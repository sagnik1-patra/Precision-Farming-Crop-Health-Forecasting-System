{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b8b041c-7738-46d8-8e01-a9e88572749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading datasets...\n",
      "  → Loaded Pesticides: (4349, 7)\n",
      "  → Loaded Rainfall: (6727, 3)\n",
      "  → Loaded Temperature: (71311, 3)\n",
      "  → Loaded Yield: (56717, 12)\n",
      "[INFO] Aggregating per-year averages...\n",
      "  → After aggregation:\n",
      "     Pesticides: (27, 2)\n",
      "     Rainfall:   (31, 1)\n",
      "     Temp:       (271, 2)\n",
      "     Yield:      (56, 6)\n",
      "[INFO] Merging yearly aggregates...\n",
      "[INFO] Final merged shape: (24, 8)\n",
      "[INFO] Features: 6 | Target: avg_temp\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "[INFO] Model summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                448       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2561 (10.00 KB)\n",
      "Trainable params: 2561 (10.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[INFO] Training model...\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "[INFO] ✅ Training complete\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "[RESULT] RMSE=0.266, MAE=0.193, R²=-4.669\n",
      "[INFO] Saving artifacts...\n",
      "[INFO] ✅ All artifacts saved in C:\\Users\\NXTWAVE\\Downloads\\Precision Farming & Crop Health Forecasting System\n",
      " - precision_model.h5\n",
      " - scaler_x.pkl\n",
      " - scaler_y.pkl\n",
      " - config.yaml\n",
      " - precision_results.json\n",
      "\n",
      "Sample predictions:\n",
      "Predicted: 17.87 | Actual: 18.25\n",
      "Predicted: 18.01 | Actual: 18.18\n",
      "Predicted: 17.62 | Actual: 17.98\n",
      "Predicted: 18.19 | Actual: 17.98\n",
      "Predicted: 17.97 | Actual: 18.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 🌾 Precision Farming & Crop Health Forecasting System\n",
    "# Author: Annan Sadr\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 📂 Paths\n",
    "# ------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Precision Farming & Crop Health Forecasting System\"\n",
    "PATH_PEST = os.path.join(BASE_DIR, \"archive\", \"pesticides.csv\")\n",
    "PATH_RAIN = os.path.join(BASE_DIR, \"archive\", \"rainfall.csv\")\n",
    "PATH_TEMP = os.path.join(BASE_DIR, \"archive\", \"temp.csv\")\n",
    "PATH_YIELD = os.path.join(BASE_DIR, \"archive\", \"yield.csv\")\n",
    "\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"precision_model.h5\")\n",
    "SCALER_X_PATH = os.path.join(BASE_DIR, \"scaler_x.pkl\")\n",
    "SCALER_Y_PATH = os.path.join(BASE_DIR, \"scaler_y.pkl\")\n",
    "CONFIG_PATH = os.path.join(BASE_DIR, \"config.yaml\")\n",
    "RESULT_PATH = os.path.join(BASE_DIR, \"precision_results.json\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🧩 Helper: Load CSV safely\n",
    "# ------------------------------------------------------------\n",
    "def load_csv_optimized(path, name):\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    print(f\"  → Loaded {name}: {df.shape}\")\n",
    "    for col in df.select_dtypes(include=[\"float64\", \"int64\"]).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "    return df\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🧩 Case-insensitive Year detection\n",
    "# ------------------------------------------------------------\n",
    "def find_year_column(df):\n",
    "    for c in df.columns:\n",
    "        if str(c).strip().lower() == \"year\":\n",
    "            return c\n",
    "    raise ValueError(f\"No 'Year' column found in: {df.columns.tolist()}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 📊 Aggregation Function\n",
    "# ------------------------------------------------------------\n",
    "def aggregate_yearly(df):\n",
    "    \"\"\"Aggregate all numeric columns per year safely (case-insensitive).\"\"\"\n",
    "    year_col = find_year_column(df)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    grouped = df.groupby(year_col, as_index=False)[numeric_cols].mean()\n",
    "    grouped = grouped.loc[:, ~grouped.columns.duplicated()]\n",
    "    grouped.rename(columns={year_col: \"Year\"}, inplace=True)  # unify column name\n",
    "    return grouped\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🧩 Load Datasets\n",
    "# ------------------------------------------------------------\n",
    "print(\"[INFO] Loading datasets...\")\n",
    "df_pest = load_csv_optimized(PATH_PEST, \"Pesticides\")\n",
    "df_rain = load_csv_optimized(PATH_RAIN, \"Rainfall\")\n",
    "df_temp = load_csv_optimized(PATH_TEMP, \"Temperature\")\n",
    "df_yield = load_csv_optimized(PATH_YIELD, \"Yield\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 📊 Aggregate numeric data per Year\n",
    "# ------------------------------------------------------------\n",
    "print(\"[INFO] Aggregating per-year averages...\")\n",
    "pest_yearly = aggregate_yearly(df_pest)\n",
    "rain_yearly = aggregate_yearly(df_rain)\n",
    "temp_yearly = aggregate_yearly(df_temp)\n",
    "yield_yearly = aggregate_yearly(df_yield)\n",
    "\n",
    "print(\"  → After aggregation:\")\n",
    "print(f\"     Pesticides: {pest_yearly.shape}\")\n",
    "print(f\"     Rainfall:   {rain_yearly.shape}\")\n",
    "print(f\"     Temp:       {temp_yearly.shape}\")\n",
    "print(f\"     Yield:      {yield_yearly.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🔗 Merge Aggregated Data\n",
    "# ------------------------------------------------------------\n",
    "print(\"[INFO] Merging yearly aggregates...\")\n",
    "df_merged = (\n",
    "    yield_yearly.merge(pest_yearly, on=\"Year\", how=\"left\")\n",
    "                .merge(rain_yearly, on=\"Year\", how=\"left\")\n",
    "                .merge(temp_yearly, on=\"Year\", how=\"left\")\n",
    ")\n",
    "\n",
    "df_merged = df_merged.dropna().reset_index(drop=True)\n",
    "print(f\"[INFO] Final merged shape: {df_merged.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🎯 Feature / Target setup\n",
    "# ------------------------------------------------------------\n",
    "target_col = \"Yield\" if \"Yield\" in df_merged.columns else df_merged.columns[-1]\n",
    "feature_cols = [c for c in df_merged.columns if c not in [\"Year\", target_col]]\n",
    "\n",
    "X = df_merged[feature_cols].values\n",
    "y = df_merged[target_col].values.reshape(-1, 1)\n",
    "print(f\"[INFO] Features: {len(feature_cols)} | Target: {target_col}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🔢 Scaling\n",
    "# ------------------------------------------------------------\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🧠 Split\n",
    "# ------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🏗️ Model\n",
    "# ------------------------------------------------------------\n",
    "model = Sequential([\n",
    "    Dense(64, activation=\"relu\", input_dim=X_train.shape[1]),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"linear\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "print(\"[INFO] Model summary:\")\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🚀 Train\n",
    "# ------------------------------------------------------------\n",
    "print(\"[INFO] Training model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200, batch_size=4,\n",
    "    validation_split=0.2, verbose=0\n",
    ")\n",
    "print(\"[INFO] ✅ Training complete\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 📈 Evaluate\n",
    "# ------------------------------------------------------------\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_true = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "r2 = 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "print(f\"[RESULT] RMSE={rmse:.3f}, MAE={mae:.3f}, R²={r2:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 💾 Save Artifacts\n",
    "# ------------------------------------------------------------\n",
    "print(\"[INFO] Saving artifacts...\")\n",
    "model.save(MODEL_PATH)\n",
    "joblib.dump(scaler_x, SCALER_X_PATH)\n",
    "joblib.dump(scaler_y, SCALER_Y_PATH)\n",
    "\n",
    "config = {\n",
    "    \"features\": feature_cols,\n",
    "    \"target\": target_col,\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"mse\",\n",
    "    \"aggregated_by\": \"Year\",\n",
    "}\n",
    "with open(CONFIG_PATH, \"w\") as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "results = {\n",
    "    \"RMSE\": float(rmse),\n",
    "    \"MAE\": float(mae),\n",
    "    \"R2_Score\": float(r2),\n",
    "    \"Dataset_Size\": int(len(df_merged)),\n",
    "    \"Features\": feature_cols,\n",
    "    \"Target\": target_col,\n",
    "}\n",
    "with open(RESULT_PATH, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"[INFO] ✅ All artifacts saved in {BASE_DIR}\")\n",
    "print(\" - precision_model.h5\")\n",
    "print(\" - scaler_x.pkl\")\n",
    "print(\" - scaler_y.pkl\")\n",
    "print(\" - config.yaml\")\n",
    "print(\" - precision_results.json\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 🧾 Sample predictions\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(min(5, len(y_pred))):\n",
    "    print(f\"Predicted: {y_pred[i][0]:.2f} | Actual: {y_true[i][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a5f14-70c0-4324-abe0-86649e5d3fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
